一、如何抓取上亿的淘宝商品

背景：尽量抓全淘宝客商品，2亿到3亿数据

考虑点：如何抓全，数据库压力，缓存三方面

1、如何去抓全这些商品

（1）考虑分类抓-分类如何选取？一级分类不考虑，用三级分类

（2）考虑关键词-关键词如何选取？尽可能细化的关键词

（3）排序，按照价格等排序

（4）原来只抓券，需放开抓取，抓全

》实际效果：一级分类有几百万，抓不完，然后依然无法抓全

2、加入分类抓后，依然抓取少，观察是否是接口原因导致抓的少

进行接口调研：分页抓取，页数达到一定后是否数据重复？

》结果：接口有问题，关键词120页后重复，分类115页后重复率提升

》观察点：每页重复率变化情况

3、商品过滤，及缓存考虑

（1）使用程序缓存，但是不能缓存太多

测试结果：缓存10w的数据就40m左右，不可缓存太多，

评估结果：预估缓存一个固定容量的缓存，采用LRUche，固定400w容量，容器多线程安全，程序重启会重新缓存

（2）redis作为缓存，需要初步预计容量

评估结果：用hash结构，10个key，平均放入，预估10到15g容量，存2亿商品。

（3）使用布隆过滤器

评估结果：程序重启会失效，使用redis的布隆过滤器，无法使用，需要安装，有版本限制4.0+

》落地：400w的固定缓存+redis hash结构，均采用key-itemId，value-时间戳形式，先从java缓存获取，拿不到再从redis获取，缓存里超过2天的商品更新，并更新缓存，缓存没有则加入缓存

4、以上版本后商品依然依然入库很少，考虑优化抓取，考虑根据价格来抓取，存在批量入库非批量入库问题

修改：

（1）先获取接口返回总量

（2）根据具体总量，对价格进行分段，一个价格区间这样去调取接口

（3）总量大的切分越细，小的区间大，直至能100页能返回完商品

（4）插入语句改成insert XXXX values （），（） update name = name形式

5、遇到瓶颈，程序越跑越慢，cpu过高，商品量依然少

定位问题：根据经验，应该是缓存出现问题，LRU在越来越大时候，查询插入性能下降

解决：

（1）cpu问题替换缓存，使用concurentHashMap，设定大小100w

（2）商品抓的少是因为有条件过滤调了，去掉即可

（3）数据库从10个线程分别写10个表，改成一个线程统一循环表入库，达到相当于休眠的作用

结果：程序运行正常，商品量提升

6、程序运行2日，redis内存过大，超过15g

问题点：

（1）当初添加缓存是为了2天更新一次，需要缓存过滤商品，实现2天再抓

（2）如果继续使用redis需要申请资源，并分片解决，并预估最终的大小

程序暂停，以抓满2亿，寻求方案

修改：

（1）使用redis的HyperLogLog，成本上需要学习，最终效果是无法满足要求

​			测试结果：300w的数据有270w以上的重复，itemId+一串固定字符串放入去测

（2）使用itemId做key放redis，设置过期时间，缓存一天，还是会占大量redis空间，方案不考虑

（3）使用布隆过滤器来做，考虑点是更新的量也大，相当于按天来缓存

结果：使用两个布隆过滤器，一个缓存2天数据，一个缓存一天数据，每天都用一天的替换掉2天的过滤器，一天的过滤器重新生成，来实现缓存的过期

7、使用布隆过滤器后抓取速度变慢

定位：初步判断是缓存问题，因为只做了缓存替换，再看源码定位存在synchronization，锁造成阻塞

考虑：综合日志考虑到前两日更新数据库的量与抓取到的商品量相差不算大，大约2.3亿商品，重复3kw，对db造成的压力提升不算大

解决：去掉布隆过滤器



总结：

（1）考虑我一天能抓到多少商品，去重后又是多少商品，即入库量，综合考虑后再决定是否使用缓存

（2）缓存考虑，从性能，多线程安全，锁，资源占用，cpu，内存等方面综合考虑使用

并发高尽量无锁

数据大尽量少缓存或者不缓存

（3）考虑db压力，尽量统一入库，通过循环入库来达到等同于休眠的作用

jdbc的批处理需要研究，并非实际的批量插入，而是一批SQL统一提交

研究：SQL支持多长，如何防注入

（4）对于缓存需要多加测试，考虑并发影响，有效的测试数据才能得出结论，尤其是使用新的缓存时候

（5）日志在分析结论时候起到重要作用，例如：抓取的商品重量，去重后多少商品